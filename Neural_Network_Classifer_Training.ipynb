{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k6F74tBwtoXq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KeypointsDataset(Dataset):\n",
        "    def __init__(self, inputs, labels, transform=None):\n",
        "      self.inputs = inputs\n",
        "      self.labels = labels\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      label = torch.tensor(self.labels[index],dtype=torch.float32)\n",
        "      input = torch.tensor(self.inputs[index],dtype=torch.float32)\n",
        "      return input,label"
      ],
      "metadata": {
        "id": "7KjWUcgatt5y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/pose_track_with_ball_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "i_nJYDSduERr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)"
      ],
      "metadata": {
        "id": "izEEwKo-vj0M"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_data = data[:,53]"
      ],
      "metadata": {
        "id": "a2J9oKfpP15G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.concatenate((data[:, :53], data[:, 54:]), axis=1) #Accidentally saved the labels not on the last index in each row so have to extract input like this\n",
        "labels_data = data[:,53]"
      ],
      "metadata": {
        "id": "eVsw2FdcR6H1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "metadata": {
        "id": "bGflKK5zci4y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = make_pipeline(Normalizer(),StandardScaler()) "
      ],
      "metadata": {
        "id": "lTicfg2nc7X1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = pipeline.fit_transform(input_data)"
      ],
      "metadata": {
        "id": "hpe0EsH5dCne"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "dump(pipeline, 'pipeline.pkl') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZQUqTFtdiyH",
        "outputId": "ea19fdaf-857a-462c-db3a-79cdd8b72e89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReversibilityClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        input_size = 57\n",
        "        self.fc1 = nn.Linear(in_features=input_size, out_features=2*input_size)\n",
        "        self.fc2 = nn.Linear(in_features=2*input_size, out_features=input_size)\n",
        "        self.fc3 = nn.Linear(in_features=input_size, out_features=1)\n",
        "        self.reLU = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.reLU(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.reLU(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hFqzN-SryYET"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "train_size = math.floor(0.7 * len(data))\n",
        "test_size = len(data) - train_size\n",
        "\n",
        "pose_dataset = KeypointsDataset(input_data, labels_data)\n",
        "\n",
        "train_dataset, test_dataset = random_split(pose_dataset, [train_size,test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
        "testing_loader = DataLoader(test_dataset, batch_size=1000, shuffle=True)"
      ],
      "metadata": {
        "id": "RMytILZgOgGB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ReversibilityClassifier()\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWq1Q-5j5Nvd",
        "outputId": "d1353126-dabd-45e0-c5e0-24e5652d1ea0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ReversibilityClassifier(\n",
              "  (fc1): Linear(in_features=57, out_features=114, bias=True)\n",
              "  (fc2): Linear(in_features=114, out_features=57, bias=True)\n",
              "  (fc3): Linear(in_features=57, out_features=1, bias=True)\n",
              "  (reLU): ReLU()\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "n_epochs = 400\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        outputs = model(inputs)\n",
        "        targets = targets.unsqueeze(1)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        total_loss += loss.detach().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    print(f\"Average loss for epoch {epoch}: {average_loss:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN8lNqyg3gL4",
        "outputId": "652fbacc-f92d-4a59-c3be-a19b1ec8c561"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average loss for epoch 0: 0.71\n",
            "Average loss for epoch 1: 0.69\n",
            "Average loss for epoch 2: 0.69\n",
            "Average loss for epoch 3: 0.69\n",
            "Average loss for epoch 4: 0.69\n",
            "Average loss for epoch 5: 0.69\n",
            "Average loss for epoch 6: 0.69\n",
            "Average loss for epoch 7: 0.68\n",
            "Average loss for epoch 8: 0.68\n",
            "Average loss for epoch 9: 0.68\n",
            "Average loss for epoch 10: 0.67\n",
            "Average loss for epoch 11: 0.67\n",
            "Average loss for epoch 12: 0.66\n",
            "Average loss for epoch 13: 0.65\n",
            "Average loss for epoch 14: 0.64\n",
            "Average loss for epoch 15: 0.64\n",
            "Average loss for epoch 16: 0.63\n",
            "Average loss for epoch 17: 0.63\n",
            "Average loss for epoch 18: 0.62\n",
            "Average loss for epoch 19: 0.61\n",
            "Average loss for epoch 20: 0.61\n",
            "Average loss for epoch 21: 0.61\n",
            "Average loss for epoch 22: 0.60\n",
            "Average loss for epoch 23: 0.60\n",
            "Average loss for epoch 24: 0.59\n",
            "Average loss for epoch 25: 0.59\n",
            "Average loss for epoch 26: 0.59\n",
            "Average loss for epoch 27: 0.59\n",
            "Average loss for epoch 28: 0.58\n",
            "Average loss for epoch 29: 0.58\n",
            "Average loss for epoch 30: 0.58\n",
            "Average loss for epoch 31: 0.58\n",
            "Average loss for epoch 32: 0.57\n",
            "Average loss for epoch 33: 0.57\n",
            "Average loss for epoch 34: 0.57\n",
            "Average loss for epoch 35: 0.57\n",
            "Average loss for epoch 36: 0.57\n",
            "Average loss for epoch 37: 0.57\n",
            "Average loss for epoch 38: 0.56\n",
            "Average loss for epoch 39: 0.56\n",
            "Average loss for epoch 40: 0.56\n",
            "Average loss for epoch 41: 0.56\n",
            "Average loss for epoch 42: 0.56\n",
            "Average loss for epoch 43: 0.56\n",
            "Average loss for epoch 44: 0.56\n",
            "Average loss for epoch 45: 0.55\n",
            "Average loss for epoch 46: 0.55\n",
            "Average loss for epoch 47: 0.56\n",
            "Average loss for epoch 48: 0.55\n",
            "Average loss for epoch 49: 0.55\n",
            "Average loss for epoch 50: 0.55\n",
            "Average loss for epoch 51: 0.55\n",
            "Average loss for epoch 52: 0.55\n",
            "Average loss for epoch 53: 0.55\n",
            "Average loss for epoch 54: 0.55\n",
            "Average loss for epoch 55: 0.55\n",
            "Average loss for epoch 56: 0.55\n",
            "Average loss for epoch 57: 0.55\n",
            "Average loss for epoch 58: 0.55\n",
            "Average loss for epoch 59: 0.55\n",
            "Average loss for epoch 60: 0.55\n",
            "Average loss for epoch 61: 0.55\n",
            "Average loss for epoch 62: 0.54\n",
            "Average loss for epoch 63: 0.55\n",
            "Average loss for epoch 64: 0.54\n",
            "Average loss for epoch 65: 0.54\n",
            "Average loss for epoch 66: 0.54\n",
            "Average loss for epoch 67: 0.54\n",
            "Average loss for epoch 68: 0.54\n",
            "Average loss for epoch 69: 0.54\n",
            "Average loss for epoch 70: 0.54\n",
            "Average loss for epoch 71: 0.54\n",
            "Average loss for epoch 72: 0.54\n",
            "Average loss for epoch 73: 0.54\n",
            "Average loss for epoch 74: 0.54\n",
            "Average loss for epoch 75: 0.54\n",
            "Average loss for epoch 76: 0.54\n",
            "Average loss for epoch 77: 0.54\n",
            "Average loss for epoch 78: 0.53\n",
            "Average loss for epoch 79: 0.53\n",
            "Average loss for epoch 80: 0.53\n",
            "Average loss for epoch 81: 0.53\n",
            "Average loss for epoch 82: 0.53\n",
            "Average loss for epoch 83: 0.53\n",
            "Average loss for epoch 84: 0.53\n",
            "Average loss for epoch 85: 0.53\n",
            "Average loss for epoch 86: 0.53\n",
            "Average loss for epoch 87: 0.53\n",
            "Average loss for epoch 88: 0.53\n",
            "Average loss for epoch 89: 0.53\n",
            "Average loss for epoch 90: 0.53\n",
            "Average loss for epoch 91: 0.53\n",
            "Average loss for epoch 92: 0.53\n",
            "Average loss for epoch 93: 0.53\n",
            "Average loss for epoch 94: 0.53\n",
            "Average loss for epoch 95: 0.53\n",
            "Average loss for epoch 96: 0.53\n",
            "Average loss for epoch 97: 0.53\n",
            "Average loss for epoch 98: 0.53\n",
            "Average loss for epoch 99: 0.53\n",
            "Average loss for epoch 100: 0.53\n",
            "Average loss for epoch 101: 0.53\n",
            "Average loss for epoch 102: 0.53\n",
            "Average loss for epoch 103: 0.53\n",
            "Average loss for epoch 104: 0.53\n",
            "Average loss for epoch 105: 0.52\n",
            "Average loss for epoch 106: 0.52\n",
            "Average loss for epoch 107: 0.52\n",
            "Average loss for epoch 108: 0.52\n",
            "Average loss for epoch 109: 0.52\n",
            "Average loss for epoch 110: 0.52\n",
            "Average loss for epoch 111: 0.52\n",
            "Average loss for epoch 112: 0.52\n",
            "Average loss for epoch 113: 0.52\n",
            "Average loss for epoch 114: 0.52\n",
            "Average loss for epoch 115: 0.52\n",
            "Average loss for epoch 116: 0.52\n",
            "Average loss for epoch 117: 0.52\n",
            "Average loss for epoch 118: 0.52\n",
            "Average loss for epoch 119: 0.52\n",
            "Average loss for epoch 120: 0.52\n",
            "Average loss for epoch 121: 0.52\n",
            "Average loss for epoch 122: 0.52\n",
            "Average loss for epoch 123: 0.52\n",
            "Average loss for epoch 124: 0.52\n",
            "Average loss for epoch 125: 0.52\n",
            "Average loss for epoch 126: 0.52\n",
            "Average loss for epoch 127: 0.52\n",
            "Average loss for epoch 128: 0.52\n",
            "Average loss for epoch 129: 0.52\n",
            "Average loss for epoch 130: 0.52\n",
            "Average loss for epoch 131: 0.52\n",
            "Average loss for epoch 132: 0.52\n",
            "Average loss for epoch 133: 0.52\n",
            "Average loss for epoch 134: 0.52\n",
            "Average loss for epoch 135: 0.52\n",
            "Average loss for epoch 136: 0.52\n",
            "Average loss for epoch 137: 0.52\n",
            "Average loss for epoch 138: 0.52\n",
            "Average loss for epoch 139: 0.52\n",
            "Average loss for epoch 140: 0.51\n",
            "Average loss for epoch 141: 0.52\n",
            "Average loss for epoch 142: 0.51\n",
            "Average loss for epoch 143: 0.52\n",
            "Average loss for epoch 144: 0.51\n",
            "Average loss for epoch 145: 0.51\n",
            "Average loss for epoch 146: 0.52\n",
            "Average loss for epoch 147: 0.51\n",
            "Average loss for epoch 148: 0.51\n",
            "Average loss for epoch 149: 0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for test_inp, test_labels in testing_loader:\n",
        "  test_inp,test_labels = test_inp.cuda(),test_labels.cuda()\n",
        "  output = model(test_inp)\n",
        "  predictions = []\n",
        "\n",
        "  for i in range(len(output)):\n",
        "    if output[i] >= 0.5:\n",
        "      predictions.append(1)\n",
        "    else:\n",
        "      predictions.append(0)\n",
        "    test_labels = test_labels.cpu()  \n",
        "  all_predictions = all_predictions + predictions\n",
        "  all_labels = all_labels + test_labels.tolist()\n",
        "  correct += (np.array(predictions)==np.array(test_labels)).sum()\n",
        "  total += float(test_labels.size(0))\n",
        "\n",
        "print (correct)\n",
        "print (total)\n",
        "print ((correct/total)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_30Jeknk7r7B",
        "outputId": "d1a8386b-d6fb-4b5e-e35a-7152a12817b6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32244\n",
            "40762.0\n",
            "79.1030862077425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"final_model.pth\")"
      ],
      "metadata": {
        "id": "TFZNRfFoz03T"
      },
      "execution_count": 115,
      "outputs": []
    }
  ]
}